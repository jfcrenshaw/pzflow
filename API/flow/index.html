
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../examples/">
      
      
        <link rel="next" href="../flowEnsemble/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.10">
    
    
      
        <title>Flow - PZFlow</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="pink" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pzflow.flow" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="PZFlow" class="md-header__button md-logo" aria-label="PZFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2.5 8.42 8.06 2 9.74l4.2 5.14-.38 6.62L12 19.09l6.18 2.41-.38-6.62L22 9.74l-6.42-1.68zm-2.62 8c.62 0 1.12.5 1.12 1.13a1.12 1.12 0 0 1-1.12 1.12c-.63 0-1.13-.5-1.13-1.12 0-.63.5-1.13 1.13-1.13m5.25 0c.62 0 1.12.5 1.12 1.13a1.12 1.12 0 0 1-1.12 1.12c-.63 0-1.13-.5-1.13-1.12 0-.63.5-1.13 1.13-1.13M9 15h6a3.249 3.249 0 0 1-6 0"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            PZFlow
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Flow
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/jfcrenshaw/pzflow" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="PZFlow" class="md-nav__button md-logo" aria-label="PZFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2.5 8.42 8.06 2 9.74l4.2 5.14-.38 6.62L12 19.09l6.18 2.41-.38-6.62L22 9.74l-6.42-1.68zm-2.62 8c.62 0 1.12.5 1.12 1.13a1.12 1.12 0 0 1-1.12 1.12c-.63 0-1.13-.5-1.13-1.12 0-.63.5-1.13 1.13-1.13m5.25 0c.62 0 1.12.5 1.12 1.13a1.12 1.12 0 0 1-1.12 1.12c-.63 0-1.13-.5-1.13-1.12 0-.63.5-1.13 1.13-1.13M9 15h6a3.249 3.249 0 0 1-6 0"/></svg>

    </a>
    PZFlow
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/jfcrenshaw/pzflow" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../install/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Install
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/conditional_demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Conditional Flows
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/gaussian_errors/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Convolving Gaussian Errors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/ensemble_demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Flow Ensembles
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/weighted/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Training Weights
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/customizing_example/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Customizing the flow
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/spherical_flow_example/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Modeling Variables with Periodic Topology
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/marginalization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Marginalizing Variables
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/nongaussian_errors/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Convolving Non-Gaussian Errors
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gotchas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Common gotchas
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    API
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bijectors/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bijectors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distributions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Flow
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Flow
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pzflow.flow" class="md-nav__link">
    <span class="md-ellipsis">
      flow
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pzflow.flow.Flow" class="md-nav__link">
    <span class="md-ellipsis">
      Flow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Flow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      log_prob
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.posterior" class="md-nav__link">
    <span class="md-ellipsis">
      posterior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.sample" class="md-nav__link">
    <span class="md-ellipsis">
      sample
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.save" class="md-nav__link">
    <span class="md-ellipsis">
      save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.set_bijector" class="md-nav__link">
    <span class="md-ellipsis">
      set_bijector
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../flowEnsemble/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    flowEnsemble
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Utils
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pzflow.flow" class="md-nav__link">
    <span class="md-ellipsis">
      flow
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pzflow.flow.Flow" class="md-nav__link">
    <span class="md-ellipsis">
      Flow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Flow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      log_prob
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.posterior" class="md-nav__link">
    <span class="md-ellipsis">
      posterior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.sample" class="md-nav__link">
    <span class="md-ellipsis">
      sample
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.save" class="md-nav__link">
    <span class="md-ellipsis">
      save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.set_bijector" class="md-nav__link">
    <span class="md-ellipsis">
      set_bijector
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pzflow.flow.Flow.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Flow</h1>

<div class="doc doc-object doc-module">



<a id="pzflow.flow"></a>
    <div class="doc doc-contents first">

        <p>Define the Flow object that defines the normalizing flow.</p>









  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="pzflow.flow.Flow" class="doc doc-heading">
            <code>Flow</code>


</h2>


    <div class="doc doc-contents ">


        <p>A normalizing flow that models tabular data.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="pzflow.flow.Flow.data_columns">data_columns</span></code></td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of DataFrame columns that the flow expects/produces.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pzflow.flow.Flow.conditional_columns">conditional_columns</span></code></td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of DataFrame columns on which the flow is conditioned.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pzflow.flow.Flow.latent">latent</span></code></td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="LatentDist (pzflow.distributions.LatentDist)" href="../distributions/#pzflow.distributions.LatentDist">LatentDist</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The latent distribution of the normalizing flow.
Has it's own sample and log_prob methods.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pzflow.flow.Flow.data_error_model">data_error_model</span></code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The error model for the data variables. See the docstring of
<strong>init</strong> for more details.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pzflow.flow.Flow.condition_error_model">condition_error_model</span></code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The error model for the conditional variables. See the docstring
of <strong>init</strong> for more details.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pzflow.flow.Flow.info">info</span></code></td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Object containing any kind of info included with the flow.
Often describes the data the flow is trained on.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>







              <details class="quote">
                <summary>Source code in <code>pzflow/flow.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  26</span>
<span class="normal">  27</span>
<span class="normal">  28</span>
<span class="normal">  29</span>
<span class="normal">  30</span>
<span class="normal">  31</span>
<span class="normal">  32</span>
<span class="normal">  33</span>
<span class="normal">  34</span>
<span class="normal">  35</span>
<span class="normal">  36</span>
<span class="normal">  37</span>
<span class="normal">  38</span>
<span class="normal">  39</span>
<span class="normal">  40</span>
<span class="normal">  41</span>
<span class="normal">  42</span>
<span class="normal">  43</span>
<span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Flow</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A normalizing flow that models tabular data.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    data_columns : tuple</span>
<span class="sd">        List of DataFrame columns that the flow expects/produces.</span>
<span class="sd">    conditional_columns : tuple</span>
<span class="sd">        List of DataFrame columns on which the flow is conditioned.</span>
<span class="sd">    latent : distributions.LatentDist</span>
<span class="sd">        The latent distribution of the normalizing flow.</span>
<span class="sd">        Has it&#39;s own sample and log_prob methods.</span>
<span class="sd">    data_error_model : Callable</span>
<span class="sd">        The error model for the data variables. See the docstring of</span>
<span class="sd">        __init__ for more details.</span>
<span class="sd">    condition_error_model : Callable</span>
<span class="sd">        The error model for the conditional variables. See the docstring</span>
<span class="sd">        of __init__ for more details.</span>
<span class="sd">    info : Any</span>
<span class="sd">        Object containing any kind of info included with the flow.</span>
<span class="sd">        Often describes the data the flow is trained on.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data_columns</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bijector</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">InitFunction</span><span class="p">,</span> <span class="n">Bijector_Info</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latent</span><span class="p">:</span> <span class="n">distributions</span><span class="o">.</span><span class="n">LatentDist</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">conditional_columns</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">data_error_model</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">condition_error_model</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">autoscale_conditions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_dictionary</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Instantiate a normalizing flow.</span>

<span class="sd">        Note that while all of the init parameters are technically optional,</span>
<span class="sd">        you must provide either data_columns OR file.</span>
<span class="sd">        In addition, if a file is provided, all other parameters must be None.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_columns : Sequence[str]; optional</span>
<span class="sd">            Tuple, list, or other container of column names.</span>
<span class="sd">            These are the columns the flow expects/produces in DataFrames.</span>
<span class="sd">        bijector : Bijector Call; optional</span>
<span class="sd">            A Bijector call that consists of the bijector InitFunction that</span>
<span class="sd">            initializes the bijector and the tuple of Bijector Info.</span>
<span class="sd">            Can be the output of any Bijector, e.g. Reverse(), Chain(...), etc.</span>
<span class="sd">            If not provided, the bijector can be set later using</span>
<span class="sd">            flow.set_bijector, or by calling flow.train, in which case the</span>
<span class="sd">            default bijector will be used. The default bijector is</span>
<span class="sd">            ShiftBounds -&gt; RollingSplineCoupling, where the range of shift</span>
<span class="sd">            bounds is learned from the training data, and the dimensions of</span>
<span class="sd">            RollingSplineCoupling is inferred. The default bijector assumes</span>
<span class="sd">            that the latent has support [-5, 5] for every dimension.</span>
<span class="sd">        latent : distributions.LatentDist; optional</span>
<span class="sd">            The latent distribution for the normalizing flow. Can be any of</span>
<span class="sd">            the distributions from pzflow.distributions. If not provided,</span>
<span class="sd">            CentBeta13 is used with input_dim = len(data_columns) and B=5.</span>
<span class="sd">        conditional_columns : Sequence[str]; optional</span>
<span class="sd">            Names of columns on which to condition the normalizing flow.</span>
<span class="sd">        data_error_model : Callable; optional</span>
<span class="sd">            A callable that defines the error model for data variables.</span>
<span class="sd">            data_error_model must take key, X, Xerr, nsamples as arguments:</span>
<span class="sd">                - key is a jax rng key, e.g. jax.random.PRNGKey(0)</span>
<span class="sd">                - X is 2D array of data variables, where the order of variables</span>
<span class="sd">                    matches the order of the columns in data_columns</span>
<span class="sd">                - Xerr is the corresponding 2D array of errors</span>
<span class="sd">                - nsamples is number of samples to draw from error distribution</span>
<span class="sd">            data_error_model must return an array of samples with the shape</span>
<span class="sd">            (X.shape[0], nsamples, X.shape[1]).</span>
<span class="sd">            If data_error_model is not provided, Gaussian error model assumed.</span>
<span class="sd">        condition_error_model : Callable; optional</span>
<span class="sd">            A callable that defines the error model for conditional variables.</span>
<span class="sd">            condition_error_model must take key, X, Xerr, nsamples, where:</span>
<span class="sd">                - key is a jax rng key, e.g. jax.random.PRNGKey(0)</span>
<span class="sd">                - X is 2D array of conditional variables, where the order of</span>
<span class="sd">                    variables matches order of columns in conditional_columns</span>
<span class="sd">                - Xerr is the corresponding 2D array of errors</span>
<span class="sd">                - nsamples is number of samples to draw from error distribution</span>
<span class="sd">            condition_error_model must return array of samples with shape</span>
<span class="sd">            (X.shape[0], nsamples, X.shape[1]).</span>
<span class="sd">            If condition_error_model is not provided, Gaussian error model</span>
<span class="sd">            assumed.</span>
<span class="sd">        autoscale_conditions : bool; default=True</span>
<span class="sd">            Sets whether or not conditions are automatically standard scaled</span>
<span class="sd">            when passed to a conditional flow. I recommend you leave as True.</span>
<span class="sd">        seed : int; default=0</span>
<span class="sd">            The random seed for initial parameters</span>
<span class="sd">        info : Any; optional</span>
<span class="sd">            An object to attach to the info attribute.</span>
<span class="sd">        file : str; optional</span>
<span class="sd">            Path to file from which to load a pretrained flow.</span>
<span class="sd">            If a file is provided, all other parameters must be None.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># validate parameters</span>
        <span class="k">if</span> <span class="n">data_columns</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">file</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must provide data_columns OR file.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">data_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">bijector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">conditional_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">latent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">data_error_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">condition_error_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If providing a file, please do not provide any other parameters.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If providing a dictionary, please do not provide any other parameters.&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only provide file or _dictionary, not both.&quot;</span><span class="p">)</span>

        <span class="c1"># if file or dictionary is provided, load everything from it</span>
        <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dict</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                    <span class="n">save_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">save_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_dictionary</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;This save file isn&#39;t a </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;It is a </span><span class="si">{</span><span class="n">save_dict</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># load columns and dimensions</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;data_columns&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;conditional_columns&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;info&quot;</span><span class="p">]</span>

            <span class="c1"># load the latent distribution</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;latent_info&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">distributions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span><span class="p">[</span><span class="mi">0</span><span class="p">])(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="c1"># load the error models</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_error_model</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;data_error_model&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">condition_error_model</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;condition_error_model&quot;</span><span class="p">]</span>

            <span class="c1"># load the bijector</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;bijector_info&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">init_fun</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">build_bijector_from_info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse</span> <span class="o">=</span> <span class="n">init_fun</span><span class="p">(</span>
                    <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span>

            <span class="c1"># load the conditional means and stds</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;condition_means&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;condition_stds&quot;</span><span class="p">]</span>

            <span class="c1"># set whether or not to automatically standard scale any</span>
            <span class="c1"># conditions passed to the normalizing flow</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_autoscale_conditions</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;autoscale_conditions&quot;</span><span class="p">]</span>

        <span class="c1"># if no file is provided, use provided parameters</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="n">info</span>

            <span class="k">if</span> <span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">conditional_columns</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">))</span>

            <span class="c1"># set whether or not to automatically standard scale any</span>
            <span class="c1"># conditions passed to the normalizing flow</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_autoscale_conditions</span> <span class="o">=</span> <span class="n">autoscale_conditions</span>

            <span class="c1"># set up the latent distribution</span>
            <span class="k">if</span> <span class="n">latent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">latent</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">CentBeta13</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">latent</span> <span class="o">=</span> <span class="n">latent</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">info</span>

            <span class="c1"># make sure the latent distribution and data_columns have the</span>
            <span class="c1"># same number of dimensions</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The latent distribution has </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">input_dim</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;dimensions, but data_columns has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;dimensions. They must match!&quot;</span>
                <span class="p">)</span>

            <span class="c1"># set up the error models</span>
            <span class="k">if</span> <span class="n">data_error_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data_error_model</span> <span class="o">=</span> <span class="n">gaussian_error_model</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data_error_model</span> <span class="o">=</span> <span class="n">data_error_model</span>
            <span class="k">if</span> <span class="n">condition_error_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">condition_error_model</span> <span class="o">=</span> <span class="n">gaussian_error_model</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">condition_error_model</span> <span class="o">=</span> <span class="n">condition_error_model</span>

            <span class="c1"># set up the bijector</span>
            <span class="k">if</span> <span class="n">bijector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_bijector</span><span class="p">(</span><span class="n">bijector</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
            <span class="c1"># if no bijector was provided, set bijector_info to None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_bijector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The bijector has not been set up yet! &quot;</span>
                <span class="s2">&quot;You can do this by calling &quot;</span>
                <span class="s2">&quot;flow.set_bijector(bijector, params), &quot;</span>
                <span class="s2">&quot;or by calling train, in which case the default &quot;</span>
                <span class="s2">&quot;bijector will be used.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_bijector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bijector</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">InitFunction</span><span class="p">,</span> <span class="n">Bijector_Info</span><span class="p">],</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Pytree</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the bijector.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bijector : Bijector Call</span>
<span class="sd">            A Bijector call that consists of the bijector InitFunction that</span>
<span class="sd">            initializes the bijector and the tuple of Bijector Info.</span>
<span class="sd">            Can be the output of any Bijector, e.g. Reverse(), Chain(...), etc.</span>
<span class="sd">        params : Pytree; optional</span>
<span class="sd">            A Pytree of bijector parameters. If not provided, the bijector</span>
<span class="sd">            will be initialized with random parameters.</span>
<span class="sd">        seed: int; default=0</span>
<span class="sd">            A random seed for initializing the bijector with random parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># set up the bijector</span>
        <span class="n">init_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="o">=</span> <span class="n">bijector</span>
        <span class="n">bijector_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse</span> <span class="o">=</span> <span class="n">init_fun</span><span class="p">(</span>
            <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
        <span class="p">)</span>

        <span class="c1"># check if params were passed</span>
        <span class="n">bijector_params</span> <span class="o">=</span> <span class="n">params</span> <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">bijector_params</span>

        <span class="c1"># save the bijector params along with the latent params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">bijector_params</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_set_default_bijector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Set the default bijector</span>
        <span class="c1"># which is ShiftBounds -&gt; RollingSplineCoupling</span>

        <span class="c1"># get the min/max for each data column</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
        <span class="n">mins</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">maxs</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># determine how many conditional columns we have</span>
        <span class="n">n_conditions</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">0</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_bijector</span><span class="p">(</span>
            <span class="n">Chain</span><span class="p">(</span>
                <span class="n">ShiftBounds</span><span class="p">(</span><span class="n">mins</span><span class="p">,</span> <span class="n">maxs</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">),</span>
                <span class="n">RollingSplineCoupling</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">),</span> <span class="n">n_conditions</span><span class="o">=</span><span class="n">n_conditions</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_conditions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="c1"># Return an array of the bijector conditions.</span>

        <span class="c1"># if this isn&#39;t a conditional flow, just return empty conditions</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># if this a conditional flow, return an array of the conditions</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">conditions</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span>
            <span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span>
        <span class="k">return</span> <span class="n">conditions</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_err_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">err_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="nb">type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">skip</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="c1"># Draw error samples for each row of inputs.</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># get list of columns</span>
        <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
            <span class="n">error_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_error_model</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;conditions&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">err_samples</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)</span>
                <span class="n">error_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">condition_error_model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;type must be `data` or `conditions`.&quot;</span><span class="p">)</span>

        <span class="c1"># make sure all relevant variables have error columns</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
            <span class="c1"># if errors not provided for the column, fill in zeros</span>
            <span class="k">if</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">_err&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">columns</span> <span class="ow">and</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">skip</span><span class="p">:</span>
                <span class="n">X</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">_err&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="c1"># if we are skipping this column, fill in nan&#39;s</span>
            <span class="k">elif</span> <span class="n">col</span> <span class="o">==</span> <span class="n">skip</span><span class="p">:</span>
                <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">nan</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">X</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">_err&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">nan</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># pull out relevant columns</span>
        <span class="n">err_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s2">&quot;_err&quot;</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">]</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Xerr</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="n">X</span><span class="p">[</span><span class="n">err_columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># generate samples</span>
        <span class="n">Xsamples</span> <span class="o">=</span> <span class="n">error_model</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Xerr</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">)</span>
        <span class="n">Xsamples</span> <span class="o">=</span> <span class="n">Xsamples</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">err_samples</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># delete the column corresponding to skip</span>
        <span class="k">if</span> <span class="n">skip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">columns</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">skip</span><span class="p">)</span>
            <span class="n">Xsamples</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">Xsamples</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># if these are samples of conditions, standard scale them!</span>
        <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;conditions&quot;</span><span class="p">:</span>
            <span class="n">Xsamples</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">Xsamples</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span>
            <span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span>

        <span class="k">return</span> <span class="n">Xsamples</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Pytree</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">conditions</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="c1"># Log prob for arrays.</span>

        <span class="c1"># calculate log_prob</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">conditions</span><span class="o">=</span><span class="n">conditions</span><span class="p">)</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">u</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_det</span>
        <span class="c1"># set NaN&#39;s to negative infinity (i.e. zero probability)</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">log_prob</span><span class="p">,</span> <span class="n">nan</span><span class="o">=-</span><span class="n">jnp</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_prob</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculates log probability density of inputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : pd.DataFrame</span>
<span class="sd">            Input data for which log probability density is calculated.</span>
<span class="sd">            Every column in self.data_columns must be present.</span>
<span class="sd">            If self.conditional_columns is not None, those must be present</span>
<span class="sd">            as well. If other columns are present, they are ignored.</span>
<span class="sd">        err_samples : int; default=None</span>
<span class="sd">            Number of samples from the error distribution to average over for</span>
<span class="sd">            the log_prob calculation. If provided, Gaussian errors are assumed,</span>
<span class="sd">            and method will look for error columns in `inputs`. Error columns</span>
<span class="sd">            must end in `_err`. E.g. the error column for the variable `u` must</span>
<span class="sd">            be `u_err`. Zero error assumed for any missing error columns.</span>
<span class="sd">        seed : int; default=None</span>
<span class="sd">            Random seed for drawing the samples with Gaussian errors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        jnp.ndarray</span>
<span class="sd">            Device array of shape (inputs.shape[0],).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check that the bijector exists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_bijector</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># convert data to an array with columns ordered</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
            <span class="c1"># get conditions</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="c1"># calculate log_prob</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">conditions</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># validate nsamples</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">err_samples</span><span class="p">,</span> <span class="nb">int</span>
            <span class="p">),</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
            <span class="k">assert</span> <span class="n">err_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
            <span class="c1"># get Gaussian samples</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e18</span><span class="p">)</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">seed</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
            <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span>
            <span class="p">)</span>
            <span class="c1"># calculate log_probs</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_probs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">grid</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">marg_rules</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">err_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">nan_to_zero</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculates posterior distributions for the provided column.</span>

<span class="sd">        Calculates the conditional posterior distribution, assuming the</span>
<span class="sd">        data values in the other columns of the DataFrame.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : pd.DataFrame</span>
<span class="sd">            Data on which the posterior distributions are conditioned.</span>
<span class="sd">            Must have columns matching self.data_columns, *except*</span>
<span class="sd">            for the column specified for the posterior (see below).</span>
<span class="sd">        column : str</span>
<span class="sd">            Name of the column for which the posterior distribution</span>
<span class="sd">            is calculated. Must be one of the columns in self.data_columns.</span>
<span class="sd">            However, whether or not this column is one of the columns in</span>
<span class="sd">            `inputs` is irrelevant.</span>
<span class="sd">        grid : jnp.ndarray</span>
<span class="sd">            Grid on which to calculate the posterior.</span>
<span class="sd">        marg_rules : dict; optional</span>
<span class="sd">            Dictionary with rules for marginalizing over missing variables.</span>
<span class="sd">            The dictionary must contain the key &quot;flag&quot;, which gives the flag</span>
<span class="sd">            that indicates a missing value. E.g. if missing values are given</span>
<span class="sd">            the value 99, the dictionary should contain {&quot;flag&quot;: 99}.</span>
<span class="sd">            The dictionary must also contain {&quot;name&quot;: callable} for any</span>
<span class="sd">            variables that will need to be marginalized over, where name is</span>
<span class="sd">            the name of the variable, and callable is a callable that takes</span>
<span class="sd">            the row of variables nad returns a grid over which to marginalize</span>
<span class="sd">            the variable. E.g. {&quot;y&quot;: lambda row: jnp.linspace(0, row[&quot;x&quot;], 10)}.</span>
<span class="sd">            Note: the callable for a given name must *always* return an array</span>
<span class="sd">            of the same length, regardless of the input row.</span>
<span class="sd">        err_samples : int; default=None</span>
<span class="sd">            Number of samples from the error distribution to average over for</span>
<span class="sd">            the posterior calculation. If provided, Gaussian errors are assumed,</span>
<span class="sd">            and method will look for error columns in `inputs`. Error columns</span>
<span class="sd">            must end in `_err`. E.g. the error column for the variable `u` must</span>
<span class="sd">            be `u_err`. Zero error assumed for any missing error columns.</span>
<span class="sd">        seed : int; default=None</span>
<span class="sd">            Random seed for drawing the samples with Gaussian errors.</span>
<span class="sd">        batch_size : int; default=None</span>
<span class="sd">            Size of batches in which to calculate posteriors. If None, all</span>
<span class="sd">            posteriors are calculated simultaneously. Simultaneous calculation</span>
<span class="sd">            is faster, but memory intensive for large data sets.</span>
<span class="sd">        normalize : boolean; default=True</span>
<span class="sd">            Whether to normalize the posterior so that it integrates to 1.</span>
<span class="sd">        nan_to_zero : bool; default=True</span>
<span class="sd">            Whether to convert NaN&#39;s to zero probability in the final pdfs.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        jnp.ndarray</span>
<span class="sd">            Device array of shape (inputs.shape[0], grid.size).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check that the bijector exists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_bijector</span><span class="p">()</span>

        <span class="c1"># get the index of the provided column, and remove it from the list</span>
        <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">columns</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
        <span class="n">columns</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>

        <span class="n">nrows</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">nrows</span> <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">batch_size</span>

        <span class="c1"># make sure indices run 0 -&gt; nrows</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># validate nsamples</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">err_samples</span><span class="p">,</span> <span class="nb">int</span>
            <span class="p">),</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
            <span class="k">assert</span> <span class="n">err_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
            <span class="c1"># set the seed</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e18</span><span class="p">)</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">seed</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># empty array to hold pdfs</span>
        <span class="n">pdfs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nrows</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">)))</span>

        <span class="c1"># if marginalization rules were passed, we will loop over the rules</span>
        <span class="c1"># and repeatedly call this method</span>
        <span class="k">if</span> <span class="n">marg_rules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if the flag is NaN, we must use jnp.isnan to check for flags</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">marg_rules</span><span class="p">[</span><span class="s2">&quot;flag&quot;</span><span class="p">]):</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">check_flags</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

            <span class="c1"># else we use jnp.isclose to check for flags</span>
            <span class="k">else</span><span class="p">:</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">check_flags</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">marg_rules</span><span class="p">[</span><span class="s2">&quot;flag&quot;</span><span class="p">])</span>

            <span class="c1"># first calculate pdfs for unflagged rows</span>
            <span class="n">unflagged_idx</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span>
                <span class="o">~</span><span class="n">check_flags</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">unflagged_pdfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">unflagged_idx</span><span class="p">],</span>
                <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
                <span class="n">grid</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
                <span class="n">err_samples</span><span class="o">=</span><span class="n">err_samples</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">nan_to_zero</span><span class="o">=</span><span class="n">nan_to_zero</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># save these pdfs in the big array</span>
            <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">unflagged_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="n">unflagged_pdfs</span><span class="p">,</span>
                <span class="n">indices_are_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">unique_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># we will keep track of all the rows we&#39;ve already calculated</span>
            <span class="c1"># posteriors for</span>
            <span class="n">already_done</span> <span class="o">=</span> <span class="n">unflagged_idx</span>

            <span class="c1"># now we will loop over the rules in marg_rules</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">rule</span> <span class="ow">in</span> <span class="n">marg_rules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># ignore the flag, because that&#39;s not a column in the data</span>
                <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;flag&quot;</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="c1"># get the list of new rows for which we need to calculate posteriors</span>
                <span class="n">flagged_idx</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">check_flags</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">])]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="n">flagged_idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">flagged_idx</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">already_done</span><span class="p">))</span>

                <span class="c1"># if flagged_idx is empty, move on!</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">flagged_idx</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="c1"># get the marginalization grid for each row</span>
                <span class="n">marg_grids</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">flagged_idx</span><span class="p">]</span>
                    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_type</span><span class="o">=</span><span class="s2">&quot;expand&quot;</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
                <span class="p">)</span>

                <span class="c1"># make a new data frame with the marginalization grids replacing</span>
                <span class="c1"># the values of the flag in the column</span>
                <span class="n">marg_inputs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                        <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">flagged_idx</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                        <span class="n">marg_grids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">columns</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">marg_inputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">marg_grids</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">marg_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># remove the error column if it&#39;s present</span>
                <span class="n">marg_inputs</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_err&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span>
                <span class="p">)</span>

                <span class="c1"># calculate posteriors for these</span>
                <span class="n">marg_pdfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                    <span class="n">inputs</span><span class="o">=</span><span class="n">marg_inputs</span><span class="p">,</span>
                    <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
                    <span class="n">grid</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
                    <span class="n">marg_rules</span><span class="o">=</span><span class="n">marg_rules</span><span class="p">,</span>
                    <span class="n">err_samples</span><span class="o">=</span><span class="n">err_samples</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">nan_to_zero</span><span class="o">=</span><span class="n">nan_to_zero</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># sum over the marginalized dimension</span>
                <span class="n">marg_pdfs</span> <span class="o">=</span> <span class="n">marg_pdfs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">flagged_idx</span><span class="p">),</span> <span class="n">marg_grids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">grid</span><span class="o">.</span><span class="n">size</span>
                <span class="p">)</span>
                <span class="n">marg_pdfs</span> <span class="o">=</span> <span class="n">marg_pdfs</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># save the new pdfs in the big array</span>
                <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">flagged_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">marg_pdfs</span><span class="p">,</span>
                    <span class="n">indices_are_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">unique_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># add these flagged indices to the list of rows already done</span>
                <span class="n">already_done</span> <span class="o">+=</span> <span class="n">flagged_idx</span>

        <span class="c1"># now for the main posterior calculation loop</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># loop through batches</span>
            <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="c1"># get the data batch</span>
                <span class="c1"># and, if this is a conditional flow, the correpsonding conditions</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

                <span class="c1"># if not drawing samples, just grab batch and conditions</span>
                <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
                <span class="c1"># if only drawing condition samples...</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
                        <span class="n">key</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span>
                    <span class="p">)</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                        <span class="n">batch</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">err_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
                    <span class="p">)</span>
                <span class="c1"># if drawing data and condition samples...</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
                        <span class="n">key</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span>
                    <span class="p">)</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
                        <span class="n">key</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="n">skip</span><span class="o">=</span><span class="n">column</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;data&quot;</span>
                    <span class="p">)</span>

                <span class="c1"># make a new copy of each row for each value of the column</span>
                <span class="c1"># for which we are calculating the posterior</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                            <span class="n">batch</span><span class="p">[:,</span> <span class="p">:</span><span class="n">idx</span><span class="p">],</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span>
                            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">jnp</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">],</span>
                        <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                            <span class="n">batch</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">:],</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span>
                            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="p">),</span>
                    <span class="p">)</span>
                <span class="p">)</span>

                <span class="c1"># make similar copies of the conditions</span>
                <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">conditions</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># calculate probability densities</span>
                <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">conditions</span>
                <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">)))</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
                <span class="c1"># if we were Gaussian sampling, average over the samples</span>
                <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">))</span>
                    <span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="c1"># add the pdfs to the bigger list</span>
                <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">prob</span><span class="p">,</span>
                    <span class="n">indices_are_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">unique_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="c1"># normalize so they integrate to one</span>
            <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span> <span class="o">/</span> <span class="n">trapezoid</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">pdfs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">grid</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nan_to_zero</span><span class="p">:</span>
            <span class="c1"># set NaN&#39;s equal to zero probability</span>
            <span class="n">pdfs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">pdfs</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pdfs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nsamples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">conditions</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_conditions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns samples from the normalizing flow.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nsamples : int; default=1</span>
<span class="sd">            The number of samples to be returned.</span>
<span class="sd">        conditions : pd.DataFrame; optional</span>
<span class="sd">            If this is a conditional flow, you must pass conditions for</span>
<span class="sd">            each sample. nsamples will be drawn for each row in conditions.</span>
<span class="sd">        save_conditions : bool; default=True</span>
<span class="sd">            If true, conditions will be saved in the DataFrame of samples</span>
<span class="sd">            that is returned.</span>
<span class="sd">        seed : int; optional</span>
<span class="sd">            Sets the random seed for the samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pd.DataFrame</span>
<span class="sd">            Pandas DataFrame of samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check that the bijector exists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_bijector</span><span class="p">()</span>

        <span class="c1"># validate nsamples</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">nsamples</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;nsamples must be a positive integer.&quot;</span>
        <span class="k">assert</span> <span class="n">nsamples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;nsamples must be a positive integer.&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">conditions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Must provide the following conditions</span><span class="se">\n</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># if this isn&#39;t a conditional flow, get empty conditions</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nsamples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># otherwise get conditions and make `nsamples` copies of each</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">conditions_idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conditions</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">conditions</span><span class="p">)</span>
            <span class="n">conditions_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">conditions_idx</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">)</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">conditions</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># draw from latent distribution</span>
        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conditions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">seed</span><span class="p">)</span>
        <span class="c1"># take the inverse back to the data distribution</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">,</span> <span class="n">conditions</span><span class="o">=</span><span class="n">conditions</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># if not conditional, this is all we need</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
        <span class="c1"># but if conditional</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">save_conditions</span><span class="p">:</span>
                <span class="c1"># unscale the conditions</span>
                <span class="n">conditions</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">conditions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span>
                <span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">conditions</span><span class="p">))),</span>
                    <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">conditions_idx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># reindex according to the conditions</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span>
                <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">conditions_idx</span><span class="p">)</span>

        <span class="c1"># return the samples!</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_save_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1">### Returns the dictionary of all flow params to be saved.</span>
        <span class="n">save_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;data_columns&quot;</span><span class="p">,</span>
            <span class="s2">&quot;conditional_columns&quot;</span><span class="p">,</span>
            <span class="s2">&quot;condition_means&quot;</span><span class="p">,</span>
            <span class="s2">&quot;condition_stds&quot;</span><span class="p">,</span>
            <span class="s2">&quot;data_error_model&quot;</span><span class="p">,</span>
            <span class="s2">&quot;condition_error_model&quot;</span><span class="p">,</span>
            <span class="s2">&quot;autoscale_conditions&quot;</span><span class="p">,</span>
            <span class="s2">&quot;info&quot;</span><span class="p">,</span>
            <span class="s2">&quot;latent_info&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bijector_info&quot;</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">save_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">save_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">key</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                    <span class="n">save_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">save_dict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Saves the flow to a file.</span>

<span class="sd">        Pickles the flow and saves it to a file that can be passed as</span>
<span class="sd">        the `file` argument during flow instantiation.</span>

<span class="sd">        WARNING: Currently, this method only works for bijectors that are</span>
<span class="sd">        implemented in the `bijectors` module. If you want to save a flow</span>
<span class="sd">        with a custom bijector, you either need to add the bijector to that</span>
<span class="sd">        module, or handle the saving and loading on your end.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        file : str</span>
<span class="sd">            Path to where the flow will be saved.</span>
<span class="sd">            Extension `.pkl` will be appended if not already present.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">save_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dict</span><span class="p">()</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">save_dict</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">val_set</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_weight</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">val_weight</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">convolve_errs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">best_params</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">initial_loss</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Trains the normalizing flow on the provided inputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : pd.DataFrame</span>
<span class="sd">            Data on which to train the normalizing flow.</span>
<span class="sd">            Must have columns matching `self.data_columns`.</span>
<span class="sd">            If training a conditional flow, must also have columns</span>
<span class="sd">            matching `self.conditional_columns`.</span>
<span class="sd">        val_set : pd.DataFrame; default=None</span>
<span class="sd">            Validation set, of same format as inputs. If provided,</span>
<span class="sd">            validation loss will be calculated at the end of each epoch.</span>
<span class="sd">        train_weight: np.ndarray; default=None</span>
<span class="sd">            Array of weights for each sample in the training set.</span>
<span class="sd">        val_weight: np.ndarray; default=None</span>
<span class="sd">            Array of weights for each sample in the validation set.</span>
<span class="sd">        epochs : int; default=100</span>
<span class="sd">            Number of epochs to train.</span>
<span class="sd">        batch_size : int; default=1024</span>
<span class="sd">            Batch size for training.</span>
<span class="sd">        optimizer : optax optimizer</span>
<span class="sd">            An optimizer from Optax. default = optax.adam(learning_rate=1e-3)</span>
<span class="sd">            see https://optax.readthedocs.io/en/latest/index.html for more.</span>
<span class="sd">        loss_fn : Callable; optional</span>
<span class="sd">            A function to calculate the loss: `loss = loss_fn(params, x, c, w)`.</span>
<span class="sd">            If not provided, will be `-mean(log_prob)`.</span>
<span class="sd">        convolve_errs : bool; default=False</span>
<span class="sd">            Whether to draw new data from the error distributions during</span>
<span class="sd">            each epoch of training. Method will look for error columns in</span>
<span class="sd">            `inputs`. Error columns must end in `_err`. E.g. the error column</span>
<span class="sd">            for the variable `u` must be `u_err`. Zero error assumed for</span>
<span class="sd">            any missing error columns. The error distribution is set during</span>
<span class="sd">            flow instantiation.</span>
<span class="sd">        patience : int; optional</span>
<span class="sd">            Factor that controls early stopping. Training will stop if the</span>
<span class="sd">            loss doesn&#39;t decrease for this number of epochs. Note if a</span>
<span class="sd">            validation set is provided, the validation loss is used.</span>
<span class="sd">        best_params : bool; default=True</span>
<span class="sd">            Whether to use the params from the epoch with the lowest loss.</span>
<span class="sd">            Note if a validation set is provided, the epoch with the lowest</span>
<span class="sd">            validation loss is chosen. If False, the params from the final</span>
<span class="sd">            epoch are saved.</span>
<span class="sd">        seed : int; default=0</span>
<span class="sd">            A random seed to control the batching and the (optional)</span>
<span class="sd">            error sampling and creating the default bijector (the latter</span>
<span class="sd">            only happens if you didn&#39;t set up the bijector during Flow</span>
<span class="sd">            instantiation).</span>
<span class="sd">        verbose : bool; default=False</span>
<span class="sd">            If true, print the training loss every 5% of epochs.</span>
<span class="sd">        progress_bar : bool; default=False</span>
<span class="sd">            If true, display a tqdm progress bar during training.</span>
<span class="sd">        initial_loss : bool; default=True</span>
<span class="sd">            If true, start by calculating the initial loss.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list</span>
<span class="sd">            List of training losses from every epoch. If no val_set provided,</span>
<span class="sd">            these are just training losses. If val_set is provided, then the</span>
<span class="sd">            first element is the list of training losses, while the second is</span>
<span class="sd">            the list of validation losses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># split the seed</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">batch_seed</span><span class="p">,</span> <span class="n">bijector_seed</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mf">1e9</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># if the bijector is None, set the default bijector</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_default_bijector</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">bijector_seed</span><span class="p">)</span>

        <span class="c1"># validate epochs</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">epochs</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;epochs must be a positive integer.&quot;</span><span class="p">)</span>

        <span class="c1"># if no loss_fn is provided, use the default loss function</span>
        <span class="k">if</span> <span class="n">loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="nd">@jit</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
                <span class="k">return</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>

        <span class="c1"># initialize the optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">optimizer</span>
        <span class="p">)</span>
        <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">)</span>

        <span class="c1"># pull out the model parameters</span>
        <span class="n">model_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span>

        <span class="c1"># define the training step function</span>
        <span class="nd">@jit</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
            <span class="n">gradients</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
            <span class="n">updates</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">opt_state</span>

        <span class="c1"># get list of data columns</span>
        <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>

        <span class="c1"># if this is a conditional flow, and autoscale_conditions == True</span>
        <span class="c1"># save the means and stds of the conditional columns</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_autoscale_conditions</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="n">inputs</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">condition_stds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="n">inputs</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">condition_stds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">condition_stds</span><span class="p">,</span> <span class="mi">1</span>
            <span class="p">)</span>

        <span class="c1"># define a function to return batches</span>
        <span class="k">if</span> <span class="n">convolve_errs</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">get_batch</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">get_batch</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;conditions&quot;</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>

        <span class="c1"># get random seed for training loop</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">batch_seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> epochs </span><span class="se">\n</span><span class="s2">Loss:&quot;</span><span class="p">)</span>

        <span class="c1"># save the initial loss</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span> <span class="k">if</span> <span class="n">train_weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">train_weight</span>
        <span class="n">W</span> <span class="o">/=</span> <span class="n">W</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">initial_loss</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
            <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xval</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_set</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
            <span class="n">Cval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">val_set</span><span class="p">)</span>
            <span class="n">Wval</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_set</span><span class="p">))</span> <span class="k">if</span> <span class="n">val_weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">val_weight</span>
            <span class="n">Wval</span> <span class="o">/=</span> <span class="n">Wval</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">initial_loss</span><span class="p">:</span>
                <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">Xval</span><span class="p">,</span> <span class="n">Cval</span><span class="p">,</span> <span class="n">Wval</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">initial_loss</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(0) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(0) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">val_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># initialize variables for early stopping</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">best_param_vals</span> <span class="o">=</span> <span class="n">model_params</span>
        <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># loop through training</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span> <span class="k">if</span> <span class="n">progress_bar</span> <span class="k">else</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">loop</span><span class="p">:</span>
            <span class="c1"># new permutation of batches</span>
            <span class="n">permute_key</span><span class="p">,</span> <span class="n">sample_key</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">permute_key</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

            <span class="c1"># loop through batches and step optimizer</span>
            <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="c1"># if sampling from the error distribution, this returns a</span>
                <span class="c1"># Gaussian sample of the batch. Else just returns batch as a</span>
                <span class="c1"># jax array</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span>
                    <span class="n">sample_key</span><span class="p">,</span>
                    <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">],</span>
                    <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">batch_conditions</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span>
                    <span class="n">sample_key</span><span class="p">,</span>
                    <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">],</span>
                    <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">batch_weights</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
                    <span class="n">W</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
                <span class="p">)</span>

                <span class="n">model_params</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">step</span><span class="p">(</span>
                    <span class="n">model_params</span><span class="p">,</span>
                    <span class="n">opt_state</span><span class="p">,</span>
                    <span class="n">batch</span><span class="p">,</span>
                    <span class="n">batch_conditions</span><span class="p">,</span>
                    <span class="n">batch_weights</span>
                <span class="p">)</span>

            <span class="c1"># save end-of-epoch training loss</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">loss_fn</span><span class="p">(</span>
                    <span class="n">model_params</span><span class="p">,</span>
                    <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
                    <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">W</span><span class="p">),</span>
                <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="c1"># and validation loss</span>
            <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">Xval</span><span class="p">,</span> <span class="n">Cval</span><span class="p">,</span> <span class="n">Wval</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="c1"># if verbose, print current loss</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="n">epoch</span> <span class="o">%</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.05</span> <span class="o">*</span> <span class="n">epochs</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="ow">or</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">epochs</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">val_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="c1"># if patience provided, we need to check for early stopping</span>
            <span class="k">if</span> <span class="n">patience</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">tracked_losses</span> <span class="o">=</span> <span class="n">losses</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tracked_losses</span> <span class="o">=</span> <span class="n">val_losses</span>

                <span class="c1"># if loss didn&#39;t improve, increase counter</span>
                <span class="c1"># and check early stopping criterion</span>
                <span class="k">if</span> <span class="n">tracked_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">best_loss</span> <span class="ow">or</span> <span class="n">jnp</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span>
                    <span class="n">tracked_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">best_loss</span>
                <span class="p">):</span>
                    <span class="n">early_stopping_counter</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="c1"># check if the early stopping criterion is met</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">patience</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="ow">and</span> <span class="n">early_stopping_counter</span> <span class="o">&gt;=</span> <span class="n">patience</span>
                    <span class="p">):</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="s2">&quot;Early stopping criterion is met.&quot;</span><span class="p">,</span>
                            <span class="sa">f</span><span class="s2">&quot;Training stopping after epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="k">break</span>
                <span class="c1"># if this is the best loss, reset the counter</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">tracked_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">best_param_vals</span> <span class="o">=</span> <span class="n">model_params</span>
                    <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># break if the training loss is NaN</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Training stopping after epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;because training loss diverged.&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># update the flow parameters with the final training state</span>
        <span class="k">if</span> <span class="n">best_params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">best_param_vals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">model_params</span>

        <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">losses</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pzflow.flow.Flow.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">data_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bijector</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">latent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">conditional_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_error_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">condition_error_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">autoscale_conditions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_dictionary</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Instantiate a normalizing flow.</p>
<p>Note that while all of the init parameters are technically optional,
you must provide either data_columns OR file.
In addition, if a file is provided, all other parameters must be None.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>data_columns</code>
            </td>
            <td>
                  <code>Sequence[str]; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple, list, or other container of column names.
These are the columns the flow expects/produces in DataFrames.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bijector</code>
            </td>
            <td>
                  <code>Bijector Call; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A Bijector call that consists of the bijector InitFunction that
initializes the bijector and the tuple of Bijector Info.
Can be the output of any Bijector, e.g. Reverse(), Chain(...), etc.
If not provided, the bijector can be set later using
flow.set_bijector, or by calling flow.train, in which case the
default bijector will be used. The default bijector is
ShiftBounds -&gt; RollingSplineCoupling, where the range of shift
bounds is learned from the training data, and the dimensions of
RollingSplineCoupling is inferred. The default bijector assumes
that the latent has support [-5, 5] for every dimension.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>latent</code>
            </td>
            <td>
                  <code>distributions.LatentDist; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The latent distribution for the normalizing flow. Can be any of
the distributions from pzflow.distributions. If not provided,
CentBeta13 is used with input_dim = len(data_columns) and B=5.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conditional_columns</code>
            </td>
            <td>
                  <code>Sequence[str]; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Names of columns on which to condition the normalizing flow.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data_error_model</code>
            </td>
            <td>
                  <code>Callable; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A callable that defines the error model for data variables.
data_error_model must take key, X, Xerr, nsamples as arguments:
    - key is a jax rng key, e.g. jax.random.PRNGKey(0)
    - X is 2D array of data variables, where the order of variables
        matches the order of the columns in data_columns
    - Xerr is the corresponding 2D array of errors
    - nsamples is number of samples to draw from error distribution
data_error_model must return an array of samples with the shape
(X.shape[0], nsamples, X.shape[1]).
If data_error_model is not provided, Gaussian error model assumed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>condition_error_model</code>
            </td>
            <td>
                  <code>Callable; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A callable that defines the error model for conditional variables.
condition_error_model must take key, X, Xerr, nsamples, where:
    - key is a jax rng key, e.g. jax.random.PRNGKey(0)
    - X is 2D array of conditional variables, where the order of
        variables matches order of columns in conditional_columns
    - Xerr is the corresponding 2D array of errors
    - nsamples is number of samples to draw from error distribution
condition_error_model must return array of samples with shape
(X.shape[0], nsamples, X.shape[1]).
If condition_error_model is not provided, Gaussian error model
assumed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>autoscale_conditions</code>
            </td>
            <td>
                  <code>bool; default=True</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sets whether or not conditions are automatically standard scaled
when passed to a conditional flow. I recommend you leave as True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code>int; default=0</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The random seed for initial parameters</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>info</code>
            </td>
            <td>
                  <code>Any; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An object to attach to the info attribute.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>file</code>
            </td>
            <td>
                  <code>str; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to file from which to load a pretrained flow.
If a file is provided, all other parameters must be None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>pzflow/flow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data_columns</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bijector</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">InitFunction</span><span class="p">,</span> <span class="n">Bijector_Info</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">latent</span><span class="p">:</span> <span class="n">distributions</span><span class="o">.</span><span class="n">LatentDist</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">conditional_columns</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">data_error_model</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">condition_error_model</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">autoscale_conditions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">info</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">_dictionary</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Instantiate a normalizing flow.</span>

<span class="sd">    Note that while all of the init parameters are technically optional,</span>
<span class="sd">    you must provide either data_columns OR file.</span>
<span class="sd">    In addition, if a file is provided, all other parameters must be None.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data_columns : Sequence[str]; optional</span>
<span class="sd">        Tuple, list, or other container of column names.</span>
<span class="sd">        These are the columns the flow expects/produces in DataFrames.</span>
<span class="sd">    bijector : Bijector Call; optional</span>
<span class="sd">        A Bijector call that consists of the bijector InitFunction that</span>
<span class="sd">        initializes the bijector and the tuple of Bijector Info.</span>
<span class="sd">        Can be the output of any Bijector, e.g. Reverse(), Chain(...), etc.</span>
<span class="sd">        If not provided, the bijector can be set later using</span>
<span class="sd">        flow.set_bijector, or by calling flow.train, in which case the</span>
<span class="sd">        default bijector will be used. The default bijector is</span>
<span class="sd">        ShiftBounds -&gt; RollingSplineCoupling, where the range of shift</span>
<span class="sd">        bounds is learned from the training data, and the dimensions of</span>
<span class="sd">        RollingSplineCoupling is inferred. The default bijector assumes</span>
<span class="sd">        that the latent has support [-5, 5] for every dimension.</span>
<span class="sd">    latent : distributions.LatentDist; optional</span>
<span class="sd">        The latent distribution for the normalizing flow. Can be any of</span>
<span class="sd">        the distributions from pzflow.distributions. If not provided,</span>
<span class="sd">        CentBeta13 is used with input_dim = len(data_columns) and B=5.</span>
<span class="sd">    conditional_columns : Sequence[str]; optional</span>
<span class="sd">        Names of columns on which to condition the normalizing flow.</span>
<span class="sd">    data_error_model : Callable; optional</span>
<span class="sd">        A callable that defines the error model for data variables.</span>
<span class="sd">        data_error_model must take key, X, Xerr, nsamples as arguments:</span>
<span class="sd">            - key is a jax rng key, e.g. jax.random.PRNGKey(0)</span>
<span class="sd">            - X is 2D array of data variables, where the order of variables</span>
<span class="sd">                matches the order of the columns in data_columns</span>
<span class="sd">            - Xerr is the corresponding 2D array of errors</span>
<span class="sd">            - nsamples is number of samples to draw from error distribution</span>
<span class="sd">        data_error_model must return an array of samples with the shape</span>
<span class="sd">        (X.shape[0], nsamples, X.shape[1]).</span>
<span class="sd">        If data_error_model is not provided, Gaussian error model assumed.</span>
<span class="sd">    condition_error_model : Callable; optional</span>
<span class="sd">        A callable that defines the error model for conditional variables.</span>
<span class="sd">        condition_error_model must take key, X, Xerr, nsamples, where:</span>
<span class="sd">            - key is a jax rng key, e.g. jax.random.PRNGKey(0)</span>
<span class="sd">            - X is 2D array of conditional variables, where the order of</span>
<span class="sd">                variables matches order of columns in conditional_columns</span>
<span class="sd">            - Xerr is the corresponding 2D array of errors</span>
<span class="sd">            - nsamples is number of samples to draw from error distribution</span>
<span class="sd">        condition_error_model must return array of samples with shape</span>
<span class="sd">        (X.shape[0], nsamples, X.shape[1]).</span>
<span class="sd">        If condition_error_model is not provided, Gaussian error model</span>
<span class="sd">        assumed.</span>
<span class="sd">    autoscale_conditions : bool; default=True</span>
<span class="sd">        Sets whether or not conditions are automatically standard scaled</span>
<span class="sd">        when passed to a conditional flow. I recommend you leave as True.</span>
<span class="sd">    seed : int; default=0</span>
<span class="sd">        The random seed for initial parameters</span>
<span class="sd">    info : Any; optional</span>
<span class="sd">        An object to attach to the info attribute.</span>
<span class="sd">    file : str; optional</span>
<span class="sd">        Path to file from which to load a pretrained flow.</span>
<span class="sd">        If a file is provided, all other parameters must be None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># validate parameters</span>
    <span class="k">if</span> <span class="n">data_columns</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">file</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must provide data_columns OR file.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="n">data_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">bijector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">conditional_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">latent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">data_error_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">condition_error_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;If providing a file, please do not provide any other parameters.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;If providing a dictionary, please do not provide any other parameters.&quot;</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only provide file or _dictionary, not both.&quot;</span><span class="p">)</span>

    <span class="c1"># if file or dictionary is provided, load everything from it</span>
    <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">_dictionary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">save_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dict</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">save_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">save_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_dictionary</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;This save file isn&#39;t a </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;It is a </span><span class="si">{</span><span class="n">save_dict</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># load columns and dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;data_columns&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;conditional_columns&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;info&quot;</span><span class="p">]</span>

        <span class="c1"># load the latent distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;latent_info&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">distributions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span><span class="p">[</span><span class="mi">0</span><span class="p">])(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># load the error models</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_error_model</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;data_error_model&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">condition_error_model</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;condition_error_model&quot;</span><span class="p">]</span>

        <span class="c1"># load the bijector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;bijector_info&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init_fun</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">build_bijector_from_info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse</span> <span class="o">=</span> <span class="n">init_fun</span><span class="p">(</span>
                <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span>

        <span class="c1"># load the conditional means and stds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;condition_means&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;condition_stds&quot;</span><span class="p">]</span>

        <span class="c1"># set whether or not to automatically standard scale any</span>
        <span class="c1"># conditions passed to the normalizing flow</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_autoscale_conditions</span> <span class="o">=</span> <span class="n">save_dict</span><span class="p">[</span><span class="s2">&quot;autoscale_conditions&quot;</span><span class="p">]</span>

    <span class="c1"># if no file is provided, use provided parameters</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="n">info</span>

        <span class="k">if</span> <span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">conditional_columns</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">))</span>

        <span class="c1"># set whether or not to automatically standard scale any</span>
        <span class="c1"># conditions passed to the normalizing flow</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_autoscale_conditions</span> <span class="o">=</span> <span class="n">autoscale_conditions</span>

        <span class="c1"># set up the latent distribution</span>
        <span class="k">if</span> <span class="n">latent</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">CentBeta13</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent</span> <span class="o">=</span> <span class="n">latent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_latent_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">info</span>

        <span class="c1"># make sure the latent distribution and data_columns have the</span>
        <span class="c1"># same number of dimensions</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The latent distribution has </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">input_dim</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;dimensions, but data_columns has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="s2">&quot;dimensions. They must match!&quot;</span>
            <span class="p">)</span>

        <span class="c1"># set up the error models</span>
        <span class="k">if</span> <span class="n">data_error_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_error_model</span> <span class="o">=</span> <span class="n">gaussian_error_model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_error_model</span> <span class="o">=</span> <span class="n">data_error_model</span>
        <span class="k">if</span> <span class="n">condition_error_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">condition_error_model</span> <span class="o">=</span> <span class="n">gaussian_error_model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">condition_error_model</span> <span class="o">=</span> <span class="n">condition_error_model</span>

        <span class="c1"># set up the bijector</span>
        <span class="k">if</span> <span class="n">bijector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_bijector</span><span class="p">(</span><span class="n">bijector</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="c1"># if no bijector was provided, set bijector_info to None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pzflow.flow.Flow.log_prob" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">err_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Calculates log probability density of inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input data for which log probability density is calculated.
Every column in self.data_columns must be present.
If self.conditional_columns is not None, those must be present
as well. If other columns are present, they are ignored.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>err_samples</code>
            </td>
            <td>
                  <code>int; default=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples from the error distribution to average over for
the log_prob calculation. If provided, Gaussian errors are assumed,
and method will look for error columns in <code>inputs</code>. Error columns
must end in <code>_err</code>. E.g. the error column for the variable <code>u</code> must
be <code>u_err</code>. Zero error assumed for any missing error columns.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code>int; default=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for drawing the samples with Gaussian errors.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jax.numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device array of shape (inputs.shape[0],).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>pzflow/flow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">log_prob</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates log probability density of inputs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    inputs : pd.DataFrame</span>
<span class="sd">        Input data for which log probability density is calculated.</span>
<span class="sd">        Every column in self.data_columns must be present.</span>
<span class="sd">        If self.conditional_columns is not None, those must be present</span>
<span class="sd">        as well. If other columns are present, they are ignored.</span>
<span class="sd">    err_samples : int; default=None</span>
<span class="sd">        Number of samples from the error distribution to average over for</span>
<span class="sd">        the log_prob calculation. If provided, Gaussian errors are assumed,</span>
<span class="sd">        and method will look for error columns in `inputs`. Error columns</span>
<span class="sd">        must end in `_err`. E.g. the error column for the variable `u` must</span>
<span class="sd">        be `u_err`. Zero error assumed for any missing error columns.</span>
<span class="sd">    seed : int; default=None</span>
<span class="sd">        Random seed for drawing the samples with Gaussian errors.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    jnp.ndarray</span>
<span class="sd">        Device array of shape (inputs.shape[0],).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># check that the bijector exists</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_bijector</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># convert data to an array with columns ordered</span>
        <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
        <span class="c1"># get conditions</span>
        <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="c1"># calculate log_prob</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">conditions</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># validate nsamples</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">err_samples</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
        <span class="k">assert</span> <span class="n">err_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
        <span class="c1"># get Gaussian samples</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e18</span><span class="p">)</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">seed</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
            <span class="n">key</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span>
        <span class="p">)</span>
        <span class="c1"># calculate log_probs</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_probs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pzflow.flow.Flow.posterior" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">posterior</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">marg_rules</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">err_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nan_to_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Calculates posterior distributions for the provided column.</p>
<p>Calculates the conditional posterior distribution, assuming the
data values in the other columns of the DataFrame.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data on which the posterior distributions are conditioned.
Must have columns matching self.data_columns, <em>except</em>
for the column specified for the posterior (see below).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>column</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the column for which the posterior distribution
is calculated. Must be one of the columns in self.data_columns.
However, whether or not this column is one of the columns in
<code>inputs</code> is irrelevant.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>grid</code>
            </td>
            <td>
                  <code><span title="jax.numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Grid on which to calculate the posterior.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>marg_rules</code>
            </td>
            <td>
                  <code>dict; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary with rules for marginalizing over missing variables.
The dictionary must contain the key "flag", which gives the flag
that indicates a missing value. E.g. if missing values are given
the value 99, the dictionary should contain {"flag": 99}.
The dictionary must also contain {"name": callable} for any
variables that will need to be marginalized over, where name is
the name of the variable, and callable is a callable that takes
the row of variables nad returns a grid over which to marginalize
the variable. E.g. {"y": lambda row: jnp.linspace(0, row["x"], 10)}.
Note: the callable for a given name must <em>always</em> return an array
of the same length, regardless of the input row.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>err_samples</code>
            </td>
            <td>
                  <code>int; default=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples from the error distribution to average over for
the posterior calculation. If provided, Gaussian errors are assumed,
and method will look for error columns in <code>inputs</code>. Error columns
must end in <code>_err</code>. E.g. the error column for the variable <code>u</code> must
be <code>u_err</code>. Zero error assumed for any missing error columns.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code>int; default=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for drawing the samples with Gaussian errors.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td>
                  <code>int; default=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Size of batches in which to calculate posteriors. If None, all
posteriors are calculated simultaneously. Simultaneous calculation
is faster, but memory intensive for large data sets.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code>boolean; default=True</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to normalize the posterior so that it integrates to 1.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nan_to_zero</code>
            </td>
            <td>
                  <code>bool; default=True</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to convert NaN's to zero probability in the final pdfs.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jax.numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device array of shape (inputs.shape[0], grid.size).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>pzflow/flow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">grid</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">marg_rules</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">err_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">nan_to_zero</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates posterior distributions for the provided column.</span>

<span class="sd">    Calculates the conditional posterior distribution, assuming the</span>
<span class="sd">    data values in the other columns of the DataFrame.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    inputs : pd.DataFrame</span>
<span class="sd">        Data on which the posterior distributions are conditioned.</span>
<span class="sd">        Must have columns matching self.data_columns, *except*</span>
<span class="sd">        for the column specified for the posterior (see below).</span>
<span class="sd">    column : str</span>
<span class="sd">        Name of the column for which the posterior distribution</span>
<span class="sd">        is calculated. Must be one of the columns in self.data_columns.</span>
<span class="sd">        However, whether or not this column is one of the columns in</span>
<span class="sd">        `inputs` is irrelevant.</span>
<span class="sd">    grid : jnp.ndarray</span>
<span class="sd">        Grid on which to calculate the posterior.</span>
<span class="sd">    marg_rules : dict; optional</span>
<span class="sd">        Dictionary with rules for marginalizing over missing variables.</span>
<span class="sd">        The dictionary must contain the key &quot;flag&quot;, which gives the flag</span>
<span class="sd">        that indicates a missing value. E.g. if missing values are given</span>
<span class="sd">        the value 99, the dictionary should contain {&quot;flag&quot;: 99}.</span>
<span class="sd">        The dictionary must also contain {&quot;name&quot;: callable} for any</span>
<span class="sd">        variables that will need to be marginalized over, where name is</span>
<span class="sd">        the name of the variable, and callable is a callable that takes</span>
<span class="sd">        the row of variables nad returns a grid over which to marginalize</span>
<span class="sd">        the variable. E.g. {&quot;y&quot;: lambda row: jnp.linspace(0, row[&quot;x&quot;], 10)}.</span>
<span class="sd">        Note: the callable for a given name must *always* return an array</span>
<span class="sd">        of the same length, regardless of the input row.</span>
<span class="sd">    err_samples : int; default=None</span>
<span class="sd">        Number of samples from the error distribution to average over for</span>
<span class="sd">        the posterior calculation. If provided, Gaussian errors are assumed,</span>
<span class="sd">        and method will look for error columns in `inputs`. Error columns</span>
<span class="sd">        must end in `_err`. E.g. the error column for the variable `u` must</span>
<span class="sd">        be `u_err`. Zero error assumed for any missing error columns.</span>
<span class="sd">    seed : int; default=None</span>
<span class="sd">        Random seed for drawing the samples with Gaussian errors.</span>
<span class="sd">    batch_size : int; default=None</span>
<span class="sd">        Size of batches in which to calculate posteriors. If None, all</span>
<span class="sd">        posteriors are calculated simultaneously. Simultaneous calculation</span>
<span class="sd">        is faster, but memory intensive for large data sets.</span>
<span class="sd">    normalize : boolean; default=True</span>
<span class="sd">        Whether to normalize the posterior so that it integrates to 1.</span>
<span class="sd">    nan_to_zero : bool; default=True</span>
<span class="sd">        Whether to convert NaN&#39;s to zero probability in the final pdfs.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    jnp.ndarray</span>
<span class="sd">        Device array of shape (inputs.shape[0], grid.size).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># check that the bijector exists</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_bijector</span><span class="p">()</span>

    <span class="c1"># get the index of the provided column, and remove it from the list</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">columns</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="n">columns</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>

    <span class="n">nrows</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">nrows</span> <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">batch_size</span>

    <span class="c1"># make sure indices run 0 -&gt; nrows</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># validate nsamples</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">err_samples</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
        <span class="k">assert</span> <span class="n">err_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;err_samples must be a positive integer.&quot;</span>
        <span class="c1"># set the seed</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e18</span><span class="p">)</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">seed</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># empty array to hold pdfs</span>
    <span class="n">pdfs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nrows</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">)))</span>

    <span class="c1"># if marginalization rules were passed, we will loop over the rules</span>
    <span class="c1"># and repeatedly call this method</span>
    <span class="k">if</span> <span class="n">marg_rules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if the flag is NaN, we must use jnp.isnan to check for flags</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">marg_rules</span><span class="p">[</span><span class="s2">&quot;flag&quot;</span><span class="p">]):</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">check_flags</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># else we use jnp.isclose to check for flags</span>
        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">check_flags</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">marg_rules</span><span class="p">[</span><span class="s2">&quot;flag&quot;</span><span class="p">])</span>

        <span class="c1"># first calculate pdfs for unflagged rows</span>
        <span class="n">unflagged_idx</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span>
            <span class="o">~</span><span class="n">check_flags</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">unflagged_pdfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">unflagged_idx</span><span class="p">],</span>
            <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
            <span class="n">grid</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
            <span class="n">err_samples</span><span class="o">=</span><span class="n">err_samples</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">nan_to_zero</span><span class="o">=</span><span class="n">nan_to_zero</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># save these pdfs in the big array</span>
        <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">unflagged_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="n">unflagged_pdfs</span><span class="p">,</span>
            <span class="n">indices_are_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">unique_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># we will keep track of all the rows we&#39;ve already calculated</span>
        <span class="c1"># posteriors for</span>
        <span class="n">already_done</span> <span class="o">=</span> <span class="n">unflagged_idx</span>

        <span class="c1"># now we will loop over the rules in marg_rules</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">rule</span> <span class="ow">in</span> <span class="n">marg_rules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># ignore the flag, because that&#39;s not a column in the data</span>
            <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;flag&quot;</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># get the list of new rows for which we need to calculate posteriors</span>
            <span class="n">flagged_idx</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">check_flags</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">name</span><span class="p">])]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">flagged_idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">flagged_idx</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">already_done</span><span class="p">))</span>

            <span class="c1"># if flagged_idx is empty, move on!</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">flagged_idx</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># get the marginalization grid for each row</span>
            <span class="n">marg_grids</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">flagged_idx</span><span class="p">]</span>
                <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_type</span><span class="o">=</span><span class="s2">&quot;expand&quot;</span><span class="p">)</span>
                <span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="c1"># make a new data frame with the marginalization grids replacing</span>
            <span class="c1"># the values of the flag in the column</span>
            <span class="n">marg_inputs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                    <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">flagged_idx</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                    <span class="n">marg_grids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">columns</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">marg_inputs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">marg_grids</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">marg_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c1"># remove the error column if it&#39;s present</span>
            <span class="n">marg_inputs</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_err&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span>
            <span class="p">)</span>

            <span class="c1"># calculate posteriors for these</span>
            <span class="n">marg_pdfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">marg_inputs</span><span class="p">,</span>
                <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
                <span class="n">grid</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
                <span class="n">marg_rules</span><span class="o">=</span><span class="n">marg_rules</span><span class="p">,</span>
                <span class="n">err_samples</span><span class="o">=</span><span class="n">err_samples</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">nan_to_zero</span><span class="o">=</span><span class="n">nan_to_zero</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># sum over the marginalized dimension</span>
            <span class="n">marg_pdfs</span> <span class="o">=</span> <span class="n">marg_pdfs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">flagged_idx</span><span class="p">),</span> <span class="n">marg_grids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">grid</span><span class="o">.</span><span class="n">size</span>
            <span class="p">)</span>
            <span class="n">marg_pdfs</span> <span class="o">=</span> <span class="n">marg_pdfs</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># save the new pdfs in the big array</span>
            <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">flagged_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="n">marg_pdfs</span><span class="p">,</span>
                <span class="n">indices_are_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">unique_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># add these flagged indices to the list of rows already done</span>
            <span class="n">already_done</span> <span class="o">+=</span> <span class="n">flagged_idx</span>

    <span class="c1"># now for the main posterior calculation loop</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># loop through batches</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># get the data batch</span>
            <span class="c1"># and, if this is a conditional flow, the correpsonding conditions</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

            <span class="c1"># if not drawing samples, just grab batch and conditions</span>
            <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
            <span class="c1"># if only drawing condition samples...</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span>
                <span class="p">)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                    <span class="n">batch</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">err_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
                <span class="p">)</span>
            <span class="c1"># if drawing data and condition samples...</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span>
                <span class="p">)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="n">skip</span><span class="o">=</span><span class="n">column</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;data&quot;</span>
                <span class="p">)</span>

            <span class="c1"># make a new copy of each row for each value of the column</span>
            <span class="c1"># for which we are calculating the posterior</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                        <span class="n">batch</span><span class="p">[:,</span> <span class="p">:</span><span class="n">idx</span><span class="p">],</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span>
                        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">jnp</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">],</span>
                    <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                        <span class="n">batch</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">:],</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span>
                        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># make similar copies of the conditions</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">conditions</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># calculate probability densities</span>
            <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">conditions</span>
            <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">)))</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
            <span class="c1"># if we were Gaussian sampling, average over the samples</span>
            <span class="k">if</span> <span class="n">err_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">err_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">))</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># add the pdfs to the bigger list</span>
            <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="n">prob</span><span class="p">,</span>
                <span class="n">indices_are_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">unique_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="c1"># normalize so they integrate to one</span>
        <span class="n">pdfs</span> <span class="o">=</span> <span class="n">pdfs</span> <span class="o">/</span> <span class="n">trapezoid</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">pdfs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">grid</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">nan_to_zero</span><span class="p">:</span>
        <span class="c1"># set NaN&#39;s equal to zero probability</span>
        <span class="n">pdfs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">pdfs</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pdfs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pzflow.flow.Flow.sample" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">nsamples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">conditions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">save_conditions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Returns samples from the normalizing flow.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>nsamples</code>
            </td>
            <td>
                  <code>int; default=1</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of samples to be returned.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conditions</code>
            </td>
            <td>
                  <code>pd.DataFrame; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If this is a conditional flow, you must pass conditions for
each sample. nsamples will be drawn for each row in conditions.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_conditions</code>
            </td>
            <td>
                  <code>bool; default=True</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If true, conditions will be saved in the DataFrame of samples
that is returned.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code>int; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sets the random seed for the samples.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Pandas DataFrame of samples.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>pzflow/flow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">nsamples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conditions</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">save_conditions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns samples from the normalizing flow.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nsamples : int; default=1</span>
<span class="sd">        The number of samples to be returned.</span>
<span class="sd">    conditions : pd.DataFrame; optional</span>
<span class="sd">        If this is a conditional flow, you must pass conditions for</span>
<span class="sd">        each sample. nsamples will be drawn for each row in conditions.</span>
<span class="sd">    save_conditions : bool; default=True</span>
<span class="sd">        If true, conditions will be saved in the DataFrame of samples</span>
<span class="sd">        that is returned.</span>
<span class="sd">    seed : int; optional</span>
<span class="sd">        Sets the random seed for the samples.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pd.DataFrame</span>
<span class="sd">        Pandas DataFrame of samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># check that the bijector exists</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_bijector</span><span class="p">()</span>

    <span class="c1"># validate nsamples</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">nsamples</span><span class="p">,</span> <span class="nb">int</span>
    <span class="p">),</span> <span class="s2">&quot;nsamples must be a positive integer.&quot;</span>
    <span class="k">assert</span> <span class="n">nsamples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;nsamples must be a positive integer.&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">conditions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Must provide the following conditions</span><span class="se">\n</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="c1"># if this isn&#39;t a conditional flow, get empty conditions</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nsamples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># otherwise get conditions and make `nsamples` copies of each</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">conditions_idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conditions</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        <span class="n">conditions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">conditions</span><span class="p">)</span>
        <span class="n">conditions_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">conditions_idx</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">)</span>
        <span class="n">conditions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">conditions</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># draw from latent distribution</span>
    <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conditions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">seed</span><span class="p">)</span>
    <span class="c1"># take the inverse back to the data distribution</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">,</span> <span class="n">conditions</span><span class="o">=</span><span class="n">conditions</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># if not conditional, this is all we need</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>
    <span class="c1"># but if conditional</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">save_conditions</span><span class="p">:</span>
            <span class="c1"># unscale the conditions</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">conditions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span>
            <span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">conditions</span><span class="p">))),</span>
                <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">conditions_idx</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># reindex according to the conditions</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span>
            <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">conditions_idx</span><span class="p">)</span>

    <span class="c1"># return the samples!</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pzflow.flow.Flow.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">file</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Saves the flow to a file.</p>
<p>Pickles the flow and saves it to a file that can be passed as
the <code>file</code> argument during flow instantiation.</p>
<p>WARNING: Currently, this method only works for bijectors that are
implemented in the <code>bijectors</code> module. If you want to save a flow
with a custom bijector, you either need to add the bijector to that
module, or handle the saving and loading on your end.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>file</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to where the flow will be saved.
Extension <code>.pkl</code> will be appended if not already present.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>pzflow/flow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Saves the flow to a file.</span>

<span class="sd">    Pickles the flow and saves it to a file that can be passed as</span>
<span class="sd">    the `file` argument during flow instantiation.</span>

<span class="sd">    WARNING: Currently, this method only works for bijectors that are</span>
<span class="sd">    implemented in the `bijectors` module. If you want to save a flow</span>
<span class="sd">    with a custom bijector, you either need to add the bijector to that</span>
<span class="sd">    module, or handle the saving and loading on your end.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    file : str</span>
<span class="sd">        Path to where the flow will be saved.</span>
<span class="sd">        Extension `.pkl` will be appended if not already present.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">save_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dict</span><span class="p">()</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">save_dict</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pzflow.flow.Flow.set_bijector" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">set_bijector</span><span class="p">(</span><span class="n">bijector</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Set the bijector.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>bijector</code>
            </td>
            <td>
                  <code>Bijector Call</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A Bijector call that consists of the bijector InitFunction that
initializes the bijector and the tuple of Bijector Info.
Can be the output of any Bijector, e.g. Reverse(), Chain(...), etc.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td>
                  <code>Pytree; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A Pytree of bijector parameters. If not provided, the bijector
will be initialized with random parameters.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A random seed for initializing the bijector with random parameters.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>pzflow/flow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">set_bijector</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">bijector</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">InitFunction</span><span class="p">,</span> <span class="n">Bijector_Info</span><span class="p">],</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Pytree</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set the bijector.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    bijector : Bijector Call</span>
<span class="sd">        A Bijector call that consists of the bijector InitFunction that</span>
<span class="sd">        initializes the bijector and the tuple of Bijector Info.</span>
<span class="sd">        Can be the output of any Bijector, e.g. Reverse(), Chain(...), etc.</span>
<span class="sd">    params : Pytree; optional</span>
<span class="sd">        A Pytree of bijector parameters. If not provided, the bijector</span>
<span class="sd">        will be initialized with random parameters.</span>
<span class="sd">    seed: int; default=0</span>
<span class="sd">        A random seed for initializing the bijector with random parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># set up the bijector</span>
    <span class="n">init_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="o">=</span> <span class="n">bijector</span>
    <span class="n">bijector_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse</span> <span class="o">=</span> <span class="n">init_fun</span><span class="p">(</span>
        <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
    <span class="p">)</span>

    <span class="c1"># check if params were passed</span>
    <span class="n">bijector_params</span> <span class="o">=</span> <span class="n">params</span> <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">bijector_params</span>

    <span class="c1"># save the bijector params along with the latent params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent</span><span class="o">.</span><span class="n">_params</span><span class="p">,</span> <span class="n">bijector_params</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pzflow.flow.Flow.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">val_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">convolve_errs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">best_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">initial_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Trains the normalizing flow on the provided inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data on which to train the normalizing flow.
Must have columns matching <code>self.data_columns</code>.
If training a conditional flow, must also have columns
matching <code>self.conditional_columns</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_set</code>
            </td>
            <td>
                  <code>pd.DataFrame; default=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Validation set, of same format as inputs. If provided,
validation loss will be calculated at the end of each epoch.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_weight</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Array of weights for each sample in the training set.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_weight</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Array of weights for each sample in the validation set.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epochs</code>
            </td>
            <td>
                  <code>int; default=100</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs to train.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td>
                  <code>int; default=1024</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch size for training.</p>
              </div>
            </td>
            <td>
                  <code>1024</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>optimizer</code>
            </td>
            <td>
                  <code>optax optimizer</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An optimizer from Optax. default = optax.adam(learning_rate=1e-3)
see https://optax.readthedocs.io/en/latest/index.html for more.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>loss_fn</code>
            </td>
            <td>
                  <code>Callable; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A function to calculate the loss: <code>loss = loss_fn(params, x, c, w)</code>.
If not provided, will be <code>-mean(log_prob)</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>convolve_errs</code>
            </td>
            <td>
                  <code>bool; default=False</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to draw new data from the error distributions during
each epoch of training. Method will look for error columns in
<code>inputs</code>. Error columns must end in <code>_err</code>. E.g. the error column
for the variable <code>u</code> must be <code>u_err</code>. Zero error assumed for
any missing error columns. The error distribution is set during
flow instantiation.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patience</code>
            </td>
            <td>
                  <code>int; optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Factor that controls early stopping. Training will stop if the
loss doesn't decrease for this number of epochs. Note if a
validation set is provided, the validation loss is used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>best_params</code>
            </td>
            <td>
                  <code>bool; default=True</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use the params from the epoch with the lowest loss.
Note if a validation set is provided, the epoch with the lowest
validation loss is chosen. If False, the params from the final
epoch are saved.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code>int; default=0</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A random seed to control the batching and the (optional)
error sampling and creating the default bijector (the latter
only happens if you didn't set up the bijector during Flow
instantiation).</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code>bool; default=False</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If true, print the training loss every 5% of epochs.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>progress_bar</code>
            </td>
            <td>
                  <code>bool; default=False</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If true, display a tqdm progress bar during training.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initial_loss</code>
            </td>
            <td>
                  <code>bool; default=True</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If true, start by calculating the initial loss.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of training losses from every epoch. If no val_set provided,
these are just training losses. If val_set is provided, then the
first element is the list of training losses, while the second is
the list of validation losses.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>pzflow/flow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">val_set</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_weight</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_weight</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">convolve_errs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">best_params</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">initial_loss</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Trains the normalizing flow on the provided inputs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    inputs : pd.DataFrame</span>
<span class="sd">        Data on which to train the normalizing flow.</span>
<span class="sd">        Must have columns matching `self.data_columns`.</span>
<span class="sd">        If training a conditional flow, must also have columns</span>
<span class="sd">        matching `self.conditional_columns`.</span>
<span class="sd">    val_set : pd.DataFrame; default=None</span>
<span class="sd">        Validation set, of same format as inputs. If provided,</span>
<span class="sd">        validation loss will be calculated at the end of each epoch.</span>
<span class="sd">    train_weight: np.ndarray; default=None</span>
<span class="sd">        Array of weights for each sample in the training set.</span>
<span class="sd">    val_weight: np.ndarray; default=None</span>
<span class="sd">        Array of weights for each sample in the validation set.</span>
<span class="sd">    epochs : int; default=100</span>
<span class="sd">        Number of epochs to train.</span>
<span class="sd">    batch_size : int; default=1024</span>
<span class="sd">        Batch size for training.</span>
<span class="sd">    optimizer : optax optimizer</span>
<span class="sd">        An optimizer from Optax. default = optax.adam(learning_rate=1e-3)</span>
<span class="sd">        see https://optax.readthedocs.io/en/latest/index.html for more.</span>
<span class="sd">    loss_fn : Callable; optional</span>
<span class="sd">        A function to calculate the loss: `loss = loss_fn(params, x, c, w)`.</span>
<span class="sd">        If not provided, will be `-mean(log_prob)`.</span>
<span class="sd">    convolve_errs : bool; default=False</span>
<span class="sd">        Whether to draw new data from the error distributions during</span>
<span class="sd">        each epoch of training. Method will look for error columns in</span>
<span class="sd">        `inputs`. Error columns must end in `_err`. E.g. the error column</span>
<span class="sd">        for the variable `u` must be `u_err`. Zero error assumed for</span>
<span class="sd">        any missing error columns. The error distribution is set during</span>
<span class="sd">        flow instantiation.</span>
<span class="sd">    patience : int; optional</span>
<span class="sd">        Factor that controls early stopping. Training will stop if the</span>
<span class="sd">        loss doesn&#39;t decrease for this number of epochs. Note if a</span>
<span class="sd">        validation set is provided, the validation loss is used.</span>
<span class="sd">    best_params : bool; default=True</span>
<span class="sd">        Whether to use the params from the epoch with the lowest loss.</span>
<span class="sd">        Note if a validation set is provided, the epoch with the lowest</span>
<span class="sd">        validation loss is chosen. If False, the params from the final</span>
<span class="sd">        epoch are saved.</span>
<span class="sd">    seed : int; default=0</span>
<span class="sd">        A random seed to control the batching and the (optional)</span>
<span class="sd">        error sampling and creating the default bijector (the latter</span>
<span class="sd">        only happens if you didn&#39;t set up the bijector during Flow</span>
<span class="sd">        instantiation).</span>
<span class="sd">    verbose : bool; default=False</span>
<span class="sd">        If true, print the training loss every 5% of epochs.</span>
<span class="sd">    progress_bar : bool; default=False</span>
<span class="sd">        If true, display a tqdm progress bar during training.</span>
<span class="sd">    initial_loss : bool; default=True</span>
<span class="sd">        If true, start by calculating the initial loss.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        List of training losses from every epoch. If no val_set provided,</span>
<span class="sd">        these are just training losses. If val_set is provided, then the</span>
<span class="sd">        first element is the list of training losses, while the second is</span>
<span class="sd">        the list of validation losses.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># split the seed</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">batch_seed</span><span class="p">,</span> <span class="n">bijector_seed</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mf">1e9</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># if the bijector is None, set the default bijector</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bijector_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_default_bijector</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">bijector_seed</span><span class="p">)</span>

    <span class="c1"># validate epochs</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">epochs</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;epochs must be a positive integer.&quot;</span><span class="p">)</span>

    <span class="c1"># if no loss_fn is provided, use the default loss function</span>
    <span class="k">if</span> <span class="n">loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

        <span class="nd">@jit</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>

    <span class="c1"># initialize the optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">optimizer</span>
    <span class="p">)</span>
    <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">)</span>

    <span class="c1"># pull out the model parameters</span>
    <span class="n">model_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span>

    <span class="c1"># define the training step function</span>
    <span class="nd">@jit</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="n">updates</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">opt_state</span>

    <span class="c1"># get list of data columns</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_columns</span><span class="p">)</span>

    <span class="c1"># if this is a conditional flow, and autoscale_conditions == True</span>
    <span class="c1"># save the means and stds of the conditional columns</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_autoscale_conditions</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_condition_means</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">condition_stds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conditional_columns</span><span class="p">)]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_condition_stds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">condition_stds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">condition_stds</span><span class="p">,</span> <span class="mi">1</span>
        <span class="p">)</span>

    <span class="c1"># define a function to return batches</span>
    <span class="k">if</span> <span class="n">convolve_errs</span><span class="p">:</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_batch</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_err_samples</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_batch</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;conditions&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>

    <span class="c1"># get random seed for training loop</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">batch_seed</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> epochs </span><span class="se">\n</span><span class="s2">Loss:&quot;</span><span class="p">)</span>

    <span class="c1"># save the initial loss</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span> <span class="k">if</span> <span class="n">train_weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">train_weight</span>
    <span class="n">W</span> <span class="o">/=</span> <span class="n">W</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">initial_loss</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Xval</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_set</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
        <span class="n">Cval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">val_set</span><span class="p">)</span>
        <span class="n">Wval</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_set</span><span class="p">))</span> <span class="k">if</span> <span class="n">val_weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">val_weight</span>
        <span class="n">Wval</span> <span class="o">/=</span> <span class="n">Wval</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">initial_loss</span><span class="p">:</span>
            <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">Xval</span><span class="p">,</span> <span class="n">Cval</span><span class="p">,</span> <span class="n">Wval</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">initial_loss</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(0) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(0) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">val_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># initialize variables for early stopping</span>
    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">best_param_vals</span> <span class="o">=</span> <span class="n">model_params</span>
    <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># loop through training</span>
    <span class="n">loop</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span> <span class="k">if</span> <span class="n">progress_bar</span> <span class="k">else</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">loop</span><span class="p">:</span>
        <span class="c1"># new permutation of batches</span>
        <span class="n">permute_key</span><span class="p">,</span> <span class="n">sample_key</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">permute_key</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># loop through batches and step optimizer</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># if sampling from the error distribution, this returns a</span>
            <span class="c1"># Gaussian sample of the batch. Else just returns batch as a</span>
            <span class="c1"># jax array</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span>
                <span class="n">sample_key</span><span class="p">,</span>
                <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">],</span>
                <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">batch_conditions</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span>
                <span class="n">sample_key</span><span class="p">,</span>
                <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">],</span>
                <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;conditions&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">batch_weights</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
                <span class="n">W</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">batch_idx</span> <span class="p">:</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="n">model_params</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">step</span><span class="p">(</span>
                <span class="n">model_params</span><span class="p">,</span>
                <span class="n">opt_state</span><span class="p">,</span>
                <span class="n">batch</span><span class="p">,</span>
                <span class="n">batch_conditions</span><span class="p">,</span>
                <span class="n">batch_weights</span>
            <span class="p">)</span>

        <span class="c1"># save end-of-epoch training loss</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">loss_fn</span><span class="p">(</span>
                <span class="n">model_params</span><span class="p">,</span>
                <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_get_conditions</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
                <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">W</span><span class="p">),</span>
            <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># and validation loss</span>
        <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">Xval</span><span class="p">,</span> <span class="n">Cval</span><span class="p">,</span> <span class="n">Wval</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># if verbose, print current loss</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">epoch</span> <span class="o">%</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.05</span> <span class="o">*</span> <span class="n">epochs</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="ow">or</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">epochs</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">val_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="c1"># if patience provided, we need to check for early stopping</span>
        <span class="k">if</span> <span class="n">patience</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">best_loss</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">tracked_losses</span> <span class="o">=</span> <span class="n">losses</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tracked_losses</span> <span class="o">=</span> <span class="n">val_losses</span>

            <span class="c1"># if loss didn&#39;t improve, increase counter</span>
            <span class="c1"># and check early stopping criterion</span>
            <span class="k">if</span> <span class="n">tracked_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">best_loss</span> <span class="ow">or</span> <span class="n">jnp</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span>
                <span class="n">tracked_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">best_loss</span>
            <span class="p">):</span>
                <span class="n">early_stopping_counter</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># check if the early stopping criterion is met</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">patience</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">early_stopping_counter</span> <span class="o">&gt;=</span> <span class="n">patience</span>
                <span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;Early stopping criterion is met.&quot;</span><span class="p">,</span>
                        <span class="sa">f</span><span class="s2">&quot;Training stopping after epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">break</span>
            <span class="c1"># if this is the best loss, reset the counter</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">tracked_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">best_param_vals</span> <span class="o">=</span> <span class="n">model_params</span>
                <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># break if the training loss is NaN</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Training stopping after epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;because training loss diverged.&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">break</span>

    <span class="c1"># update the flow parameters with the final training state</span>
    <span class="k">if</span> <span class="n">best_params</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">best_param_vals</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">model_params</span>

    <span class="k">if</span> <span class="n">val_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">losses</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>